<!doctype html>
<html>
<head></head>
<body>
<script>
  function makeArray(size, opt) {
    var arr = [];
    opt = opt || {};
    for (var i = 0; i < size; i++) {
      if (opt.value) {
        arr.push(value);
      } else if (opt.cb) {
        arr.push(opt.cb(i));
      } else {
        arr.push(Math.random());
      }
    }

    return arr;
  }

  var activators = {
    ReLU: function (x) {
      return Math.max(0, x);
    },
    Softmax: function (x) {
      return 1 / (1 + Math.pow(Math.E, -x));
    },
  };

  /**
   *
   * @param {number} inputs
   * @constructor
   */
  function Neuron(inputs) {
    this.weights = makeArray(inputs);
    this.bias = Math.random();
  }

  /**
   *
   * @param {Array} inputs
   */
  Neuron.prototype.applyInputs = function (inputs) {
    if (inputs.length !== this.weights.length) {
      throw new Error('Size of inputs and and weights vector must match');
    }

    var weights = this.weights;
    var sum = inputs.reduce(function (acc, input, i) {
      return acc + input * weights[i];
    }, 0);

    return sum + this.bias;
  };

  /**
   *
   * @param {Array<number>} layersConfig List of integers, where list element indicates layer number, and value is amount of nodes in it. Example [3, 4, 5, 6] makes input layer with 3 nodes, output layer with 6 nodes, and two hidden layers with 4 and 5 nodes respectively.
   * @param {Object=} settings
   * @constructor
   */
  function NN(layersConfig, settings) {
    /** @type {Array<Neuron>} layers */
    this.layers = layersConfig.map(function (size, i) {
      if (i === 0) {
        return;
      }

      var inputs = layersConfig[i - 1];
      return makeArray(size, {
        cb: function () {
          return new Neuron(inputs);
        }
      });
    });

    this.layers.shift();

    this.hiddenActivator = settings.hiddenActivator || activators.ReLU;
    this.outputActivator = settings.outputActivator || activators.Softmax;
  }

  NN.prototype._forward = function (inputs, i) {
    i = i || 0;
    if (i >= this.layers.length) {
      return inputs;
    }

    var layer = this.layers[i];
    if (layer[0].weights.length !== inputs.length) {
      throw new Error('Input size mismatch during forward prop step at layer #' + i);
    }

    var outputLayer = i === this.layers.length - 1;
    var activation = outputLayer ? this.outputActivator : this.hiddenActivator;
    var output = layer.map((neuron) => activation(neuron.applyInputs(inputs)));

    return this._forward(output, i + 1);
  };

  /**
   *
   * @param {Array<number>} expected Labels vector at a given input x
   * @param {Array<number>} actual Activations vector from the entire network form a given input x
   * @private
   */
  NN.prototype._cost = function(expected, actual) {
    if (expected.length !== actual.length) {
      throw new Error('Input size mismatch during cost calculation');
    }

    // SUM(||expected - actual||^2)
    var sum = expected.reduce((acc, el, i) => {
      var diff = el - actual[i];
      return acc + diff * diff;
    }, 0);

    return 0.5 * sum;
  };


  // -----------------------
  // -----------------------


  function main() {
    var net = new NN([2, 10, 10, 3], { outputActivator: activators.ReLU });
    var pixels = [
      [0, 0, 255, 0, 0],
    ];
    var trainX = pixels.map((sample) => sample.slice(0, 2));
    var trainY = pixels.map((sample) => sample.slice(2));

    console.log('Training data:');
    console.table(trainX.slice(0, 5));
    console.table(trainY.slice(0, 5));

    var activation = net._forward(trainX[0]);
    console.log('Activation', activation);

    var cost = net._cost(trainY[0], activation);
    console.log('Cost', cost);
  }

  main();
</script>
</body>
</html>
